{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data preparation\n",
    "# game --> team\n",
    "# team --> game\n",
    "# write all data into csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model construction\n",
    "# read data \n",
    "data = pd.read_csv(\"all_data.csv\")\n",
    "target = data['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.71615720524\n",
      "confusion matrix:\n",
      " [[88 37]\n",
      " [28 76]]\n",
      "P: 0.672566371681\n",
      "R: 0.730769230769\n",
      "log_loss: 0.532172798705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:6: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:7: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n"
     ]
    }
   ],
   "source": [
    "# seed difference\n",
    "\n",
    "seed = data['different_seed']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(seed, target, random_state=0)\n",
    "x_train = x_train.reshape(-1,1)\n",
    "x_test = x_test.reshape(-1,1)\n",
    "\n",
    "# logistic regression\n",
    "\n",
    "log = LogisticRegression()\n",
    "print(\"accuracy:\",log.fit(x_train, y_train).score(x_test,y_test));\n",
    "\n",
    "pred = log.predict(x_test)\n",
    "confusion = confusion_matrix(y_test,pred)\n",
    "print(\"confusion matrix:\\n\",confusion);\n",
    "print(\"P:\",precision_score(y_test,pred));\n",
    "print(\"R:\",recall_score(y_test,pred))\n",
    "\n",
    "pred_prob = log.fit(x_train, y_train).predict_proba(x_test)\n",
    "print(\"log_loss:\",log_loss(y_test,pred_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result</th>\n",
       "      <th>team1</th>\n",
       "      <th>team2</th>\n",
       "      <th>Season</th>\n",
       "      <th>diff_score</th>\n",
       "      <th>diff_fgm</th>\n",
       "      <th>diff_fga</th>\n",
       "      <th>diff_fgm3</th>\n",
       "      <th>diff_fga3</th>\n",
       "      <th>diff_ftm</th>\n",
       "      <th>diff_fta</th>\n",
       "      <th>diff_or</th>\n",
       "      <th>diff_dr</th>\n",
       "      <th>diff_ast</th>\n",
       "      <th>diff_to</th>\n",
       "      <th>diff_stl</th>\n",
       "      <th>diff_blk</th>\n",
       "      <th>diff_pf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1112</td>\n",
       "      <td>1125</td>\n",
       "      <td>2013</td>\n",
       "      <td>3.618750</td>\n",
       "      <td>2.602083</td>\n",
       "      <td>0.310417</td>\n",
       "      <td>0.643750</td>\n",
       "      <td>1.006250</td>\n",
       "      <td>-2.229167</td>\n",
       "      <td>-2.679167</td>\n",
       "      <td>-2.164583</td>\n",
       "      <td>-1.885417</td>\n",
       "      <td>1.956250</td>\n",
       "      <td>0.472917</td>\n",
       "      <td>2.595833</td>\n",
       "      <td>-1.172917</td>\n",
       "      <td>1.856250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1116</td>\n",
       "      <td>1137</td>\n",
       "      <td>2006</td>\n",
       "      <td>-8.012236</td>\n",
       "      <td>-3.516129</td>\n",
       "      <td>-8.914349</td>\n",
       "      <td>0.324805</td>\n",
       "      <td>-1.220245</td>\n",
       "      <td>-1.304783</td>\n",
       "      <td>-1.796440</td>\n",
       "      <td>-2.883204</td>\n",
       "      <td>-0.459399</td>\n",
       "      <td>-0.962180</td>\n",
       "      <td>1.095662</td>\n",
       "      <td>0.272525</td>\n",
       "      <td>-4.439377</td>\n",
       "      <td>0.616240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1137</td>\n",
       "      <td>1139</td>\n",
       "      <td>2013</td>\n",
       "      <td>1.174242</td>\n",
       "      <td>-0.154356</td>\n",
       "      <td>0.457386</td>\n",
       "      <td>1.920455</td>\n",
       "      <td>6.216856</td>\n",
       "      <td>-0.437500</td>\n",
       "      <td>0.989583</td>\n",
       "      <td>2.574811</td>\n",
       "      <td>-2.246212</td>\n",
       "      <td>-0.558712</td>\n",
       "      <td>3.835227</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>-1.759470</td>\n",
       "      <td>3.404356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1112</td>\n",
       "      <td>1156</td>\n",
       "      <td>2009</td>\n",
       "      <td>-7.218750</td>\n",
       "      <td>-2.625000</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>-1.437500</td>\n",
       "      <td>-0.312500</td>\n",
       "      <td>-0.531250</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>-0.656250</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>2.625000</td>\n",
       "      <td>0.218750</td>\n",
       "      <td>2.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1124</td>\n",
       "      <td>1160</td>\n",
       "      <td>2012</td>\n",
       "      <td>-7.991477</td>\n",
       "      <td>-3.372159</td>\n",
       "      <td>-4.312500</td>\n",
       "      <td>-1.164773</td>\n",
       "      <td>-1.535985</td>\n",
       "      <td>-0.082386</td>\n",
       "      <td>1.825758</td>\n",
       "      <td>-2.558712</td>\n",
       "      <td>1.340909</td>\n",
       "      <td>-3.352273</td>\n",
       "      <td>-1.285985</td>\n",
       "      <td>-1.761364</td>\n",
       "      <td>-1.386364</td>\n",
       "      <td>-0.542614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   result  team1  team2  Season  diff_score  diff_fgm  diff_fga  diff_fgm3  \\\n",
       "0       1   1112   1125    2013    3.618750  2.602083  0.310417   0.643750   \n",
       "1       0   1116   1137    2006   -8.012236 -3.516129 -8.914349   0.324805   \n",
       "2       0   1137   1139    2013    1.174242 -0.154356  0.457386   1.920455   \n",
       "3       1   1112   1156    2009   -7.218750 -2.625000  0.093750  -1.437500   \n",
       "4       1   1124   1160    2012   -7.991477 -3.372159 -4.312500  -1.164773   \n",
       "\n",
       "   diff_fga3  diff_ftm  diff_fta   diff_or   diff_dr  diff_ast   diff_to  \\\n",
       "0   1.006250 -2.229167 -2.679167 -2.164583 -1.885417  1.956250  0.472917   \n",
       "1  -1.220245 -1.304783 -1.796440 -2.883204 -0.459399 -0.962180  1.095662   \n",
       "2   6.216856 -0.437500  0.989583  2.574811 -2.246212 -0.558712  3.835227   \n",
       "3  -0.312500 -0.531250  0.093750  0.468750 -0.656250 -1.000000 -0.125000   \n",
       "4  -1.535985 -0.082386  1.825758 -2.558712  1.340909 -3.352273 -1.285985   \n",
       "\n",
       "   diff_stl  diff_blk   diff_pf  \n",
       "0  2.595833 -1.172917  1.856250  \n",
       "1  0.272525 -4.439377  0.616240  \n",
       "2  2.166667 -1.759470  3.404356  \n",
       "3  2.625000  0.218750  2.750000  \n",
       "4 -1.761364 -1.386364 -0.542614  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all other difference\n",
    "data0 = data.iloc[:,51:65]\n",
    "data1 = data.iloc[:,1:3]\n",
    "data0 = pd.concat([data1,data0], axis=1)\n",
    "data0 = pd.concat([data['team1'],data0], axis=1)\n",
    "data0 = pd.concat([data['result'],data0], axis=1)\n",
    "data0 = data0.dropna()\n",
    "data0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = data0.iloc[:,4:18]\n",
    "target = data0['result']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df, target, random_state=0)\n",
    "\n",
    "x_train_scaled = scaler.fit(x_train).transform(x_train)\n",
    "x_test_scaled = scaler.fit(x_train).transform(x_test)\n",
    "df_scaled = scaler.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.638766519824\n",
      "confusion matrix:\n",
      " [[72 40]\n",
      " [42 73]]\n",
      "P: 0.646017699115\n",
      "R: 0.634782608696\n",
      "log_loss: 0.605148199814\n"
     ]
    }
   ],
   "source": [
    "# logistic regression\n",
    "log = LogisticRegression()\n",
    "print(\"accuracy:\",log.fit(x_train, y_train).score(x_test,y_test));\n",
    "\n",
    "pred = log.predict(x_test)\n",
    "confusion = confusion_matrix(y_test,pred)\n",
    "print(\"confusion matrix:\\n\",confusion);\n",
    "print(\"P:\",precision_score(y_test,pred));\n",
    "print(\"R:\",recall_score(y_test,pred));\n",
    "\n",
    "pred_prob = log.fit(x_train, y_train).predict_proba(x_test)\n",
    "print(\"log_loss:\",log_loss(y_test,pred_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.678414096916\n",
      "confusion matrix:\n",
      " [[78 34]\n",
      " [39 76]]\n",
      "P: 0.690909090909\n",
      "R: 0.660869565217\n",
      "log_loss: 0.603924386801\n"
     ]
    }
   ],
   "source": [
    "# logistic regression using scaled data\n",
    "log = LogisticRegression()\n",
    "print(\"accuracy:\",log.fit(x_train_scaled, y_train).score(x_test_scaled,y_test));\n",
    "\n",
    "pred = log.predict(x_test_scaled)\n",
    "confusion = confusion_matrix(y_test,pred)\n",
    "print(\"confusion matrix:\\n\",confusion);\n",
    "print(\"P:\",precision_score(y_test,pred));\n",
    "print(\"R:\",recall_score(y_test,pred));\n",
    "\n",
    "pred_prob = log.fit(x_train_scaled, y_train).predict_proba(x_test_scaled)\n",
    "print(\"log_loss:\",log_loss(y_test,pred_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.546255506608\n",
      "confusion matrix:\n",
      " [[82 30]\n",
      " [73 42]]\n",
      "P: 0.583333333333\n",
      "R: 0.365217391304\n",
      "log_loss: 0.685906620939\n"
     ]
    }
   ],
   "source": [
    "# svm\n",
    "clf = svm.SVC()\n",
    "\n",
    "print(\"accuracy:\",clf.fit(x_train, y_train).score(x_test,y_test));\n",
    "\n",
    "pred = clf.fit(x_train, y_train).predict(x_test)\n",
    "confusion = confusion_matrix(y_test,pred)\n",
    "print(\"confusion matrix:\\n\",confusion);\n",
    "print(\"P:\",precision_score(y_test,pred));\n",
    "print(\"R:\",recall_score(y_test,pred));\n",
    "\n",
    "clf = svm.SVC(probability=True)\n",
    "pred_prob = clf.fit(x_train, y_train).predict_proba(x_test)\n",
    "print(\"log_loss:\",log_loss(y_test,pred_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.660792951542\n",
      "confusion matrix:\n",
      " [[82 30]\n",
      " [47 68]]\n",
      "P: 0.69387755102\n",
      "R: 0.591304347826\n",
      "log_loss: 0.604725501994\n"
     ]
    }
   ],
   "source": [
    "# svm using scaled data\n",
    "clf = svm.SVC()\n",
    "\n",
    "print(\"accuracy:\",clf.fit(x_train_scaled, y_train).score(x_test_scaled,y_test));\n",
    "\n",
    "pred = clf.fit(x_train_scaled, y_train).predict(x_test_scaled)\n",
    "confusion = confusion_matrix(y_test,pred)\n",
    "print(\"confusion matrix:\\n\",confusion);\n",
    "print(\"P:\",precision_score(y_test,pred));\n",
    "print(\"R:\",recall_score(y_test,pred));\n",
    "\n",
    "clf = svm.SVC(probability=True)\n",
    "pred_prob = clf.fit(x_train_scaled, y_train).predict_proba(x_test_scaled)\n",
    "print(\"log_loss:\",log_loss(y_test,pred_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result</th>\n",
       "      <th>team1</th>\n",
       "      <th>team2</th>\n",
       "      <th>Season</th>\n",
       "      <th>different_seed</th>\n",
       "      <th>diff_score</th>\n",
       "      <th>diff_fgm</th>\n",
       "      <th>diff_fga</th>\n",
       "      <th>diff_fgm3</th>\n",
       "      <th>diff_fga3</th>\n",
       "      <th>diff_ftm</th>\n",
       "      <th>diff_fta</th>\n",
       "      <th>diff_or</th>\n",
       "      <th>diff_dr</th>\n",
       "      <th>diff_ast</th>\n",
       "      <th>diff_to</th>\n",
       "      <th>diff_stl</th>\n",
       "      <th>diff_blk</th>\n",
       "      <th>diff_pf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1112</td>\n",
       "      <td>1125</td>\n",
       "      <td>2013</td>\n",
       "      <td>-5</td>\n",
       "      <td>3.618750</td>\n",
       "      <td>2.602083</td>\n",
       "      <td>0.310417</td>\n",
       "      <td>0.643750</td>\n",
       "      <td>1.006250</td>\n",
       "      <td>-2.229167</td>\n",
       "      <td>-2.679167</td>\n",
       "      <td>-2.164583</td>\n",
       "      <td>-1.885417</td>\n",
       "      <td>1.956250</td>\n",
       "      <td>0.472917</td>\n",
       "      <td>2.595833</td>\n",
       "      <td>-1.172917</td>\n",
       "      <td>1.856250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1116</td>\n",
       "      <td>1137</td>\n",
       "      <td>2006</td>\n",
       "      <td>-1</td>\n",
       "      <td>-8.012236</td>\n",
       "      <td>-3.516129</td>\n",
       "      <td>-8.914349</td>\n",
       "      <td>0.324805</td>\n",
       "      <td>-1.220245</td>\n",
       "      <td>-1.304783</td>\n",
       "      <td>-1.796440</td>\n",
       "      <td>-2.883204</td>\n",
       "      <td>-0.459399</td>\n",
       "      <td>-0.962180</td>\n",
       "      <td>1.095662</td>\n",
       "      <td>0.272525</td>\n",
       "      <td>-4.439377</td>\n",
       "      <td>0.616240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1137</td>\n",
       "      <td>1139</td>\n",
       "      <td>2013</td>\n",
       "      <td>5</td>\n",
       "      <td>1.174242</td>\n",
       "      <td>-0.154356</td>\n",
       "      <td>0.457386</td>\n",
       "      <td>1.920455</td>\n",
       "      <td>6.216856</td>\n",
       "      <td>-0.437500</td>\n",
       "      <td>0.989583</td>\n",
       "      <td>2.574811</td>\n",
       "      <td>-2.246212</td>\n",
       "      <td>-0.558712</td>\n",
       "      <td>3.835227</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>-1.759470</td>\n",
       "      <td>3.404356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1112</td>\n",
       "      <td>1156</td>\n",
       "      <td>2009</td>\n",
       "      <td>-1</td>\n",
       "      <td>-7.218750</td>\n",
       "      <td>-2.625000</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>-1.437500</td>\n",
       "      <td>-0.312500</td>\n",
       "      <td>-0.531250</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>-0.656250</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>2.625000</td>\n",
       "      <td>0.218750</td>\n",
       "      <td>2.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1124</td>\n",
       "      <td>1160</td>\n",
       "      <td>2012</td>\n",
       "      <td>-8</td>\n",
       "      <td>-7.991477</td>\n",
       "      <td>-3.372159</td>\n",
       "      <td>-4.312500</td>\n",
       "      <td>-1.164773</td>\n",
       "      <td>-1.535985</td>\n",
       "      <td>-0.082386</td>\n",
       "      <td>1.825758</td>\n",
       "      <td>-2.558712</td>\n",
       "      <td>1.340909</td>\n",
       "      <td>-3.352273</td>\n",
       "      <td>-1.285985</td>\n",
       "      <td>-1.761364</td>\n",
       "      <td>-1.386364</td>\n",
       "      <td>-0.542614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   result  team1  team2  Season  different_seed  diff_score  diff_fgm  \\\n",
       "0       1   1112   1125    2013              -5    3.618750  2.602083   \n",
       "1       0   1116   1137    2006              -1   -8.012236 -3.516129   \n",
       "2       0   1137   1139    2013               5    1.174242 -0.154356   \n",
       "3       1   1112   1156    2009              -1   -7.218750 -2.625000   \n",
       "4       1   1124   1160    2012              -8   -7.991477 -3.372159   \n",
       "\n",
       "   diff_fga  diff_fgm3  diff_fga3  diff_ftm  diff_fta   diff_or   diff_dr  \\\n",
       "0  0.310417   0.643750   1.006250 -2.229167 -2.679167 -2.164583 -1.885417   \n",
       "1 -8.914349   0.324805  -1.220245 -1.304783 -1.796440 -2.883204 -0.459399   \n",
       "2  0.457386   1.920455   6.216856 -0.437500  0.989583  2.574811 -2.246212   \n",
       "3  0.093750  -1.437500  -0.312500 -0.531250  0.093750  0.468750 -0.656250   \n",
       "4 -4.312500  -1.164773  -1.535985 -0.082386  1.825758 -2.558712  1.340909   \n",
       "\n",
       "   diff_ast   diff_to  diff_stl  diff_blk   diff_pf  \n",
       "0  1.956250  0.472917  2.595833 -1.172917  1.856250  \n",
       "1 -0.962180  1.095662  0.272525 -4.439377  0.616240  \n",
       "2 -0.558712  3.835227  2.166667 -1.759470  3.404356  \n",
       "3 -1.000000 -0.125000  2.625000  0.218750  2.750000  \n",
       "4 -3.352273 -1.285985 -1.761364 -1.386364 -0.542614  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all difference with seed difference\n",
    "data0 = data.iloc[:,50:65]\n",
    "data1 = data.iloc[:,1:3]\n",
    "data0 = pd.concat([data1,data0], axis=1)\n",
    "data0 = pd.concat([data['team1'],data0], axis=1)\n",
    "data0 = pd.concat([data['result'],data0], axis=1)\n",
    "data0 = data0.dropna()\n",
    "data0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.709251101322\n",
      "confusion matrix:\n",
      " [[83 29]\n",
      " [37 78]]\n",
      "P: 0.728971962617\n",
      "R: 0.678260869565\n",
      "log_loss: 0.548221113352\n"
     ]
    }
   ],
   "source": [
    "df = data0.iloc[:,4:18]\n",
    "target = data0['result']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df, target, random_state=0)\n",
    "\n",
    "x_train_scaled = scaler.fit(x_train).transform(x_train)\n",
    "x_test_scaled = scaler.fit(x_train).transform(x_test)\n",
    "df_scaled = scaler.fit_transform(df)\n",
    "\n",
    "# logistic regression\n",
    "log = LogisticRegression()\n",
    "print(\"accuracy:\",log.fit(x_train, y_train).score(x_test,y_test));\n",
    "\n",
    "pred = log.predict(x_test)\n",
    "confusion = confusion_matrix(y_test,pred)\n",
    "print(\"confusion matrix:\\n\",confusion);\n",
    "print(\"P:\",precision_score(y_test,pred));\n",
    "print(\"R:\",recall_score(y_test,pred));\n",
    "\n",
    "pred_prob = log.fit(x_train, y_train).predict_proba(x_test)\n",
    "print(\"log_loss:\",log_loss(y_test,pred_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.718061674009\n",
      "confusion matrix:\n",
      " [[86 26]\n",
      " [38 77]]\n",
      "P: 0.747572815534\n",
      "R: 0.669565217391\n",
      "log_loss: 0.550236931041\n"
     ]
    }
   ],
   "source": [
    "# logistic regression using scaled data\n",
    "log = LogisticRegression()\n",
    "print(\"accuracy:\",log.fit(x_train_scaled, y_train).score(x_test_scaled,y_test));\n",
    "\n",
    "pred = log.predict(x_test_scaled)\n",
    "confusion = confusion_matrix(y_test,pred)\n",
    "print(\"confusion matrix:\\n\",confusion);\n",
    "print(\"P:\",precision_score(y_test,pred));\n",
    "print(\"R:\",recall_score(y_test,pred));\n",
    "\n",
    "pred_prob = log.fit(x_train_scaled, y_train).predict_proba(x_test_scaled)\n",
    "print(\"log_loss:\",log_loss(y_test,pred_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.581497797357\n",
      "confusion matrix:\n",
      " [[92 20]\n",
      " [75 40]]\n",
      "P: 0.666666666667\n",
      "R: 0.347826086957\n",
      "log_loss: 0.661858129374\n"
     ]
    }
   ],
   "source": [
    "# svm\n",
    "clf = svm.SVC()\n",
    "\n",
    "print(\"accuracy:\",clf.fit(x_train, y_train).score(x_test,y_test));\n",
    "\n",
    "pred = clf.fit(x_train, y_train).predict(x_test)\n",
    "confusion = confusion_matrix(y_test,pred)\n",
    "print(\"confusion matrix:\\n\",confusion);\n",
    "print(\"P:\",precision_score(y_test,pred));\n",
    "print(\"R:\",recall_score(y_test,pred));\n",
    "\n",
    "clf = svm.SVC(probability=True)\n",
    "pred_prob = clf.fit(x_train, y_train).predict_proba(x_test)\n",
    "print(\"log_loss:\",log_loss(y_test,pred_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.726872246696\n",
      "confusion matrix:\n",
      " [[86 26]\n",
      " [36 79]]\n",
      "P: 0.752380952381\n",
      "R: 0.686956521739\n",
      "log_loss: 0.544766890539\n"
     ]
    }
   ],
   "source": [
    "# svm using scaled data\n",
    "clf = svm.SVC()\n",
    "\n",
    "print(\"accuracy:\",clf.fit(x_train_scaled, y_train).score(x_test_scaled,y_test));\n",
    "\n",
    "pred = clf.fit(x_train_scaled, y_train).predict(x_test_scaled)\n",
    "confusion = confusion_matrix(y_test,pred)\n",
    "print(\"confusion matrix:\\n\",confusion);\n",
    "print(\"P:\",precision_score(y_test,pred));\n",
    "print(\"R:\",recall_score(y_test,pred));\n",
    "\n",
    "clf = svm.SVC(probability=True)\n",
    "pred_prob = clf.fit(x_train_scaled, y_train).predict_proba(x_test_scaled)\n",
    "print(\"log_loss:\",log_loss(y_test,pred_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.656387665198\n",
      "confusion matrix:\n",
      " [[77 35]\n",
      " [43 72]]\n",
      "P: 0.672897196262\n",
      "R: 0.626086956522\n",
      "log_loss: 0.632094655657\n"
     ]
    }
   ],
   "source": [
    "# only score and win rate with scale\n",
    "data0 = data.dropna()\n",
    "df = data0[['score1','score2','rate1','rate2']]\n",
    "target = data0['result']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df, target, random_state=0)\n",
    "\n",
    "x_train_scaled = scaler.fit(x_train).transform(x_train)\n",
    "x_test_scaled = scaler.fit(x_train).transform(x_test)\n",
    "df_scaled = scaler.fit_transform(df)\n",
    "\n",
    "# logistic regression\n",
    "log = LogisticRegression()\n",
    "print(\"accuracy:\",log.fit(x_train, y_train).score(x_test,y_test));\n",
    "\n",
    "pred = log.predict(x_test)\n",
    "confusion = confusion_matrix(y_test,pred)\n",
    "print(\"confusion matrix:\\n\",confusion);\n",
    "print(\"P:\",precision_score(y_test,pred));\n",
    "print(\"R:\",recall_score(y_test,pred));\n",
    "\n",
    "pred_prob = log.fit(x_train, y_train).predict_proba(x_test)\n",
    "print(\"log_loss:\",log_loss(y_test,pred_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>team2</th>\n",
       "      <th>Season</th>\n",
       "      <th>fgm1</th>\n",
       "      <th>fga1</th>\n",
       "      <th>fgm31</th>\n",
       "      <th>fga31</th>\n",
       "      <th>ftm1</th>\n",
       "      <th>fta1</th>\n",
       "      <th>or1</th>\n",
       "      <th>...</th>\n",
       "      <th>diff_fga3</th>\n",
       "      <th>diff_ftm</th>\n",
       "      <th>diff_fta</th>\n",
       "      <th>diff_or</th>\n",
       "      <th>diff_dr</th>\n",
       "      <th>diff_ast</th>\n",
       "      <th>diff_to</th>\n",
       "      <th>diff_stl</th>\n",
       "      <th>diff_blk</th>\n",
       "      <th>diff_pf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1125</td>\n",
       "      <td>2013</td>\n",
       "      <td>27.633333</td>\n",
       "      <td>55.966667</td>\n",
       "      <td>8.300000</td>\n",
       "      <td>22.100000</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>18.133333</td>\n",
       "      <td>9.366667</td>\n",
       "      <td>...</td>\n",
       "      <td>1.006250</td>\n",
       "      <td>-2.229167</td>\n",
       "      <td>-2.679167</td>\n",
       "      <td>-2.164583</td>\n",
       "      <td>-1.885417</td>\n",
       "      <td>1.956250</td>\n",
       "      <td>0.472917</td>\n",
       "      <td>2.595833</td>\n",
       "      <td>-1.172917</td>\n",
       "      <td>1.856250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1137</td>\n",
       "      <td>2006</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>48.827586</td>\n",
       "      <td>6.034483</td>\n",
       "      <td>15.586207</td>\n",
       "      <td>14.275862</td>\n",
       "      <td>20.655172</td>\n",
       "      <td>9.310345</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.220245</td>\n",
       "      <td>-1.304783</td>\n",
       "      <td>-1.796440</td>\n",
       "      <td>-2.883204</td>\n",
       "      <td>-0.459399</td>\n",
       "      <td>-0.962180</td>\n",
       "      <td>1.095662</td>\n",
       "      <td>0.272525</td>\n",
       "      <td>-4.439377</td>\n",
       "      <td>0.616240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1139</td>\n",
       "      <td>2013</td>\n",
       "      <td>23.939394</td>\n",
       "      <td>53.363636</td>\n",
       "      <td>6.545455</td>\n",
       "      <td>19.060606</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>20.333333</td>\n",
       "      <td>11.606061</td>\n",
       "      <td>...</td>\n",
       "      <td>6.216856</td>\n",
       "      <td>-0.437500</td>\n",
       "      <td>0.989583</td>\n",
       "      <td>2.574811</td>\n",
       "      <td>-2.246212</td>\n",
       "      <td>-0.558712</td>\n",
       "      <td>3.835227</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>-1.759470</td>\n",
       "      <td>3.404356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1156</td>\n",
       "      <td>2009</td>\n",
       "      <td>23.031250</td>\n",
       "      <td>54.156250</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>15.343750</td>\n",
       "      <td>14.156250</td>\n",
       "      <td>20.093750</td>\n",
       "      <td>11.562500</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.312500</td>\n",
       "      <td>-0.531250</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>-0.656250</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>2.625000</td>\n",
       "      <td>0.218750</td>\n",
       "      <td>2.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1160</td>\n",
       "      <td>2012</td>\n",
       "      <td>22.718750</td>\n",
       "      <td>51.687500</td>\n",
       "      <td>5.562500</td>\n",
       "      <td>16.312500</td>\n",
       "      <td>15.281250</td>\n",
       "      <td>22.250000</td>\n",
       "      <td>9.562500</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.535985</td>\n",
       "      <td>-0.082386</td>\n",
       "      <td>1.825758</td>\n",
       "      <td>-2.558712</td>\n",
       "      <td>1.340909</td>\n",
       "      <td>-3.352273</td>\n",
       "      <td>-1.285985</td>\n",
       "      <td>-1.761364</td>\n",
       "      <td>-1.386364</td>\n",
       "      <td>-0.542614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  team2  Season       fgm1       fga1     fgm31      fga31  \\\n",
       "0           0   1125    2013  27.633333  55.966667  8.300000  22.100000   \n",
       "1           1   1137    2006  23.000000  48.827586  6.034483  15.586207   \n",
       "2           2   1139    2013  23.939394  53.363636  6.545455  19.060606   \n",
       "3           3   1156    2009  23.031250  54.156250  4.750000  15.343750   \n",
       "4           4   1160    2012  22.718750  51.687500  5.562500  16.312500   \n",
       "\n",
       "        ftm1       fta1        or1    ...     diff_fga3  diff_ftm  diff_fta  \\\n",
       "0  13.333333  18.133333   9.366667    ...      1.006250 -2.229167 -2.679167   \n",
       "1  14.275862  20.655172   9.310345    ...     -1.220245 -1.304783 -1.796440   \n",
       "2  14.000000  20.333333  11.606061    ...      6.216856 -0.437500  0.989583   \n",
       "3  14.156250  20.093750  11.562500    ...     -0.312500 -0.531250  0.093750   \n",
       "4  15.281250  22.250000   9.562500    ...     -1.535985 -0.082386  1.825758   \n",
       "\n",
       "    diff_or   diff_dr  diff_ast   diff_to  diff_stl  diff_blk   diff_pf  \n",
       "0 -2.164583 -1.885417  1.956250  0.472917  2.595833 -1.172917  1.856250  \n",
       "1 -2.883204 -0.459399 -0.962180  1.095662  0.272525 -4.439377  0.616240  \n",
       "2  2.574811 -2.246212 -0.558712  3.835227  2.166667 -1.759470  3.404356  \n",
       "3  0.468750 -0.656250 -1.000000 -0.125000  2.625000  0.218750  2.750000  \n",
       "4 -2.558712  1.340909 -3.352273 -1.285985 -1.761364 -1.386364 -0.542614  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
